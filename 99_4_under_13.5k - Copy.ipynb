{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sb6o6mtZ93Rs"
      },
      "outputs": [],
      "source": [
        "# Importing all the libraries in\n",
        "import torch # Import pytorch\n",
        "import torch.nn as nn # For creating Neural Network Models\n",
        "import torch.nn.functional as F #\n",
        "import torch.optim as optim # Importing optimizer from pytorch library\n",
        "from torchvision import datasets, transforms # Importing datasets and transform function to run over the dataset\n",
        "# !pip install torchsummary # Installing Torch summary to view the model summary\n",
        "from torchsummary import summary # Importing the summary function from the installed torchsummary library\n",
        "from tqdm.auto import tqdm\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt # To plot graphs\n",
        "from utils import data_transformation, plot_dataset,plot_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_WMGYRL93Rv",
        "outputId": "827b99cd-e625-41b8-a344-0b1f09ee3bdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "  # checking if Cuda is available, it is available it returns True, else returns False\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\") # Assign Device to Cuda or CPU based on avaiablily\n",
        "\n",
        "torch.manual_seed(1)\n",
        "# if cuda:\n",
        "torch.cuda.manual_seed(1)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcL-lfhW80s6",
        "outputId": "fd701722-19b0-433a-c5c1-d90b849a18b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# current Batch size is set to 128, meaning the dataset will be split in different batches,\n",
        "# each batch will contain 128 datapoints or here images.\n",
        "batch_size = 128\n",
        "\n",
        "# Calling a Dataloader function that takes in the dataset, batchsize and shuffle.\n",
        "# Here the dataset is mnist and is loaded from the datasets function loaded from\n",
        "# torch vision library\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    # loading MNIST dataset to data directory, train is true therefore loading the\n",
        "    # dataset from the training directory, download is true indicating the data needs\n",
        "    # to be downloaded. Performing a Transformation Operation, here there are two operations\n",
        "    # ToTensor and Normalize and each is performed one after the other. ToTensor operation is\n",
        "    # used to convert it tensor and Normalize takes in mean and std of the dataset to normalize\n",
        "    # in the input image. shuffle indicates the data will be loaded randomly\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomApply([transforms.CenterCrop(22), ], p=0.1),\n",
        "                        transforms.Resize((28, 28)),\n",
        "                        transforms.RandomRotation((-15., 15.), fill=0),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)\n",
        "                        ) # these are the MNIST dataset mean and std values of dataset set\n",
        "                    ])),\n",
        "\n",
        "    batch_size=batch_size, shuffle=True,num_workers = 4,pin_memory = True)\n",
        "  # Performing the same operation to create the test data, therefore train is set to false and\n",
        "  # is loaded to test_loader\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)) # these are the MNIST dataset mean and std values of training set\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True,num_workers = 4,pin_memory = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIzwXzFH8qnt",
        "outputId": "7b56c846-d62c-4898-d142-46cd0264838f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 12, 26, 26]             108\n",
            "       BatchNorm2d-2           [-1, 12, 26, 26]              24\n",
            "         Dropout2d-3           [-1, 12, 26, 26]               0\n",
            "            Conv2d-4           [-1, 12, 24, 24]           1,296\n",
            "       BatchNorm2d-5           [-1, 12, 24, 24]              24\n",
            "         Dropout2d-6           [-1, 12, 24, 24]               0\n",
            "            Conv2d-7           [-1, 20, 22, 22]           2,160\n",
            "       BatchNorm2d-8           [-1, 20, 22, 22]              40\n",
            "            Conv2d-9           [-1, 16, 22, 22]             320\n",
            "        MaxPool2d-10           [-1, 16, 11, 11]               0\n",
            "           Conv2d-11             [-1, 16, 9, 9]           2,304\n",
            "      BatchNorm2d-12             [-1, 16, 9, 9]              32\n",
            "        Dropout2d-13             [-1, 16, 9, 9]               0\n",
            "           Conv2d-14             [-1, 16, 7, 7]           2,304\n",
            "      BatchNorm2d-15             [-1, 16, 7, 7]              32\n",
            "        Dropout2d-16             [-1, 16, 7, 7]               0\n",
            "           Conv2d-17             [-1, 16, 7, 7]           2,304\n",
            "      BatchNorm2d-18             [-1, 16, 7, 7]              32\n",
            "           Conv2d-19             [-1, 16, 5, 5]           2,304\n",
            "      BatchNorm2d-20             [-1, 16, 5, 5]              32\n",
            "           Conv2d-21             [-1, 10, 5, 5]             160\n",
            "        AvgPool2d-22             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 13,476\n",
            "Trainable params: 13,476\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.63\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 0.69\n",
            "----------------------------------------------------------------\n",
            "Epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.09288953989744186 batch_id=468 Accuracy = 86.06: 100%|██████████| 469/469 [00:41<00:00, 11.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0596, Accuracy: 9831/10000 (98.31%)\n",
            "\n",
            "Epoch 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.08603569120168686 batch_id=468 Accuracy = 96.73: 100%|██████████| 469/469 [00:26<00:00, 17.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0393, Accuracy: 9887/10000 (98.87%)\n",
            "\n",
            "Epoch 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.09299459308385849 batch_id=468 Accuracy = 97.33: 100%|██████████| 469/469 [00:26<00:00, 17.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0356, Accuracy: 9894/10000 (98.94%)\n",
            "\n",
            "Epoch 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.05956103280186653 batch_id=468 Accuracy = 97.75: 100%|██████████| 469/469 [00:25<00:00, 18.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0273, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "Epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.1060471460223198 batch_id=468 Accuracy = 98.26: 100%|██████████| 469/469 [00:26<00:00, 17.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0212, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "Epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.019504962489008904 batch_id=468 Accuracy = 98.33: 100%|██████████| 469/469 [00:25<00:00, 18.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0206, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "Epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.08032000809907913 batch_id=468 Accuracy = 98.35: 100%|██████████| 469/469 [00:25<00:00, 18.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0201, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "Epoch 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.055094972252845764 batch_id=468 Accuracy = 98.35: 100%|██████████| 469/469 [00:25<00:00, 18.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0201, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "Epoch 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.0748290941119194 batch_id=468 Accuracy = 98.40: 100%|██████████| 469/469 [00:26<00:00, 17.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0201, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "Epoch 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.04344501718878746 batch_id=468 Accuracy = 98.47: 100%|██████████| 469/469 [00:26<00:00, 18.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0197, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "Epoch 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.00788253266364336 batch_id=468 Accuracy = 98.39: 100%|██████████| 469/469 [00:26<00:00, 18.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0199, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "Epoch 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.025182878598570824 batch_id=468 Accuracy = 98.46: 100%|██████████| 469/469 [00:25<00:00, 18.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0195, Accuracy: 9937/10000 (99.37%)\n",
            "\n",
            "Epoch 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.055106114596128464 batch_id=468 Accuracy = 98.41: 100%|██████████| 469/469 [00:28<00:00, 16.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0200, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "Epoch 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.06913025677204132 batch_id=468 Accuracy = 98.56: 100%|██████████| 469/469 [00:25<00:00, 18.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0198, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "Epoch 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.060922861099243164 batch_id=468 Accuracy = 98.45: 100%|██████████| 469/469 [00:25<00:00, 18.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0194, Accuracy: 9937/10000 (99.37%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from model import Net1\n",
        "model = Net1().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1, verbose=False)\n",
        "num_epochs = 15\n",
        "train_acc,train_losses,test_acc,test_losses = model.run(num_epochs,model,device,train_loader,test_loader,optimizer, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ie4FhX2q87s5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
