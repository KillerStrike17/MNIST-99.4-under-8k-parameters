{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sb6o6mtZ93Rs"
      },
      "outputs": [],
      "source": [
        "# Importing all the libraries in\n",
        "import torch # Import pytorch\n",
        "import torch.nn as nn # For creating Neural Network Models\n",
        "import torch.nn.functional as F #\n",
        "import torch.optim as optim # Importing optimizer from pytorch library\n",
        "from torchvision import datasets, transforms # Importing datasets and transform function to run over the dataset\n",
        "# !pip install torchsummary # Installing Torch summary to view the model summary\n",
        "from torchsummary import summary # Importing the summary function from the installed torchsummary library\n",
        "from tqdm.auto import tqdm\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt # To plot graphs\n",
        "from utils import data_transformation, plot_dataset,plot_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_WMGYRL93Rv",
        "outputId": "1125647a-4307-4935-cf2d-87bd5079bd4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "  # checking if Cuda is available, it is available it returns True, else returns False\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\") # Assign Device to Cuda or CPU based on avaiablily\n",
        "\n",
        "torch.manual_seed(1)\n",
        "# if cuda:\n",
        "torch.cuda.manual_seed(1)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDu4x6z393Rw",
        "outputId": "5c821144-7765-4b6f-f619-1f7e046d0055"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# current Batch size is set to 128, meaning the dataset will be split in different batches,\n",
        "# each batch will contain 128 datapoints or here images.\n",
        "batch_size = 128\n",
        "\n",
        "# Calling a Dataloader function that takes in the dataset, batchsize and shuffle.\n",
        "# Here the dataset is mnist and is loaded from the datasets function loaded from\n",
        "# torch vision library\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    # loading MNIST dataset to data directory, train is true therefore loading the\n",
        "    # dataset from the training directory, download is true indicating the data needs\n",
        "    # to be downloaded. Performing a Transformation Operation, here there are two operations\n",
        "    # ToTensor and Normalize and each is performed one after the other. ToTensor operation is\n",
        "    # used to convert it tensor and Normalize takes in mean and std of the dataset to normalize\n",
        "    # in the input image. shuffle indicates the data will be loaded randomly\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        # transforms.RandomApply([transforms.CenterCrop(22), ], p=0.1),\n",
        "                        # transforms.Resize((28, 28)),\n",
        "                        # transforms.RandomRotation((-15., 15.), fill=0),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)\n",
        "                        ) # these are the MNIST dataset mean and std values of dataset set\n",
        "                    ])),\n",
        "\n",
        "    batch_size=batch_size, shuffle=True,num_workers = 4,pin_memory = True)\n",
        "  # Performing the same operation to create the test data, therefore train is set to false and\n",
        "  # is loaded to test_loader\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)) # these are the MNIST dataset mean and std values of training set\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True,num_workers = 4,pin_memory = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGIia5Zm93Ry",
        "outputId": "90cd9ee7-0a39-4f20-e4be-f5584e89db03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.09583064168691635 batch_id=468 Accuracy = 89.05: 100%|██████████| 469/469 [00:31<00:00, 14.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0715, Accuracy: 9820/10000 (98.20%)\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.04321979358792305 batch_id=468 Accuracy = 97.37: 100%|██████████| 469/469 [00:25<00:00, 18.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0536, Accuracy: 9863/10000 (98.63%)\n",
            "\n",
            "Epoch: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.06086182966828346 batch_id=468 Accuracy = 98.01: 100%|██████████| 469/469 [00:25<00:00, 18.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0386, Accuracy: 9883/10000 (98.83%)\n",
            "\n",
            "Epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.03211347386240959 batch_id=468 Accuracy = 98.25: 100%|██████████| 469/469 [00:26<00:00, 17.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0400, Accuracy: 9879/10000 (98.79%)\n",
            "\n",
            "Epoch: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.049990613013505936 batch_id=468 Accuracy = 98.42: 100%|██████████| 469/469 [00:27<00:00, 17.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0271, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "Epoch: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.07416544109582901 batch_id=468 Accuracy = 98.61: 100%|██████████| 469/469 [00:26<00:00, 17.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0297, Accuracy: 9919/10000 (99.19%)\n",
            "\n",
            "Epoch: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.02841780334711075 batch_id=468 Accuracy = 98.62: 100%|██████████| 469/469 [00:26<00:00, 17.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0318, Accuracy: 9897/10000 (98.97%)\n",
            "\n",
            "Epoch: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.013437452726066113 batch_id=468 Accuracy = 98.70: 100%|██████████| 469/469 [00:27<00:00, 17.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0257, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "Epoch: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.0197892002761364 batch_id=468 Accuracy = 98.92: 100%|██████████| 469/469 [00:29<00:00, 15.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0209, Accuracy: 9937/10000 (99.37%)\n",
            "\n",
            "Epoch: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.056764546781778336 batch_id=468 Accuracy = 98.98: 100%|██████████| 469/469 [00:27<00:00, 17.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0206, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "Epoch: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.015227423049509525 batch_id=468 Accuracy = 99.07: 100%|██████████| 469/469 [00:26<00:00, 17.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0199, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "Epoch: 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.054361552000045776 batch_id=468 Accuracy = 98.98: 100%|██████████| 469/469 [00:25<00:00, 18.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0197, Accuracy: 9944/10000 (99.44%)\n",
            "\n",
            "Epoch: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.047301024198532104 batch_id=468 Accuracy = 99.06: 100%|██████████| 469/469 [00:26<00:00, 17.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0199, Accuracy: 9942/10000 (99.42%)\n",
            "\n",
            "Epoch: 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.026556359604001045 batch_id=468 Accuracy = 99.05: 100%|██████████| 469/469 [00:26<00:00, 17.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0194, Accuracy: 9945/10000 (99.45%)\n",
            "\n",
            "Epoch: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.005879692267626524 batch_id=468 Accuracy = 99.08: 100%|██████████| 469/469 [00:27<00:00, 17.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0192, Accuracy: 9941/10000 (99.41%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from model import Net3\n",
        "model = Net3().to(device)\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1, verbose=False)\n",
        "num_epochs = 15\n",
        "train_acc,train_losses,test_acc,test_losses = model.run(num_epochs,model,device,train_loader,test_loader,optimizer, scheduler)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
